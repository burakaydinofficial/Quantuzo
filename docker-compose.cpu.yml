# CPU Override for slow inference
# ================================
# Usage: docker compose -f docker-compose.yml -f docker-compose.cpu.yml up
# Or via run.sh: ./scripts/run.sh --cpu -m MODEL -k KV -d DATASET
#
# Use this when running large models on CPU where inference is slow.
# Sets longer API timeouts to prevent request cancellation.

services:
  swe-agent:
    environment:
      # Extended timeout for slow CPU inference (1 hour)
      # At 2 TPS, 3600s allows ~7200 tokens generation
      - HTTPX_TIMEOUT=3600
      - OPENAI_TIMEOUT=3600
      - LITELLM_REQUEST_TIMEOUT=3600
      # Single worker for CPU to avoid resource contention
      - WORKERS=1
