# GLM-4.7-Flash MXFP4 Model Configuration
# ========================================
# 30B MoE, DeepSeek2 architecture
# Source: https://huggingface.co/ubergarm/GLM-4.7-Flash-GGUF (community)

MODEL_REPO=ubergarm/GLM-4.7-Flash-GGUF
MODEL_FILE=GLM-4.7-Flash-MXFP4.gguf
MODEL_NAME=glm-4.7-flash-mxfp4

# Size: 15.9 GB
# Minimum RAM: 20GB (with Q4 KV cache)
# Note: Community GGUF, not official
