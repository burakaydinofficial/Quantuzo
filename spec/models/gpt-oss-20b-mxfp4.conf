# GPT-OSS-20B MXFP4 Model Configuration
# ======================================
# 21B total / 3.6B active MoE from OpenAI
# Source: https://huggingface.co/ggml-org/gpt-oss-20b-GGUF

MODEL_REPO=ggml-org/gpt-oss-20b-GGUF
MODEL_FILE=gpt-oss-20b-mxfp4.gguf
MODEL_NAME=gpt-oss-20b-mxfp4

# Size: 12.1 GB
# Minimum RAM: 16GB (with Q4 KV cache)
# Note: MXFP4 is the recommended quantization for this model
