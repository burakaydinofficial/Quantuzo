# Runtime Configuration
# =====================
# Base settings for all benchmark runs.
# Model configs can override these values.

# Context size for inference
# Note: Results with different context sizes are not directly comparable
CTX_SIZE=65536

# CPU thread settings (adjust based on your system)
THREADS=16
THREADS_BATCH=8

# Evaluation parallelism
EVAL_WORKERS=8
